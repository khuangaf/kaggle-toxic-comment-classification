{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, LeakyReLU, merge, Conv2D, Conv1D, PReLU,ELU,Concatenate, Convolution1D\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout, CuDNNGRU,MaxPooling1D,MaxPool2D,MaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers.core import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import cPickle as pickle\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "embedding_dim = 300\n",
    "TIME_STEPS = 100\n",
    "SINGLE_ATTENTION_VECTOR = False\n",
    "with h5py.File(''.join(['toxic_token_external.h5']), 'r') as hf:\n",
    "    X_t = hf['X_t'].value\n",
    "    X_te = hf['X_te'].value\n",
    "    y = hf['y'].value\n",
    "    embedding_matrix = hf['embedding_matrix'].value\n",
    "with open('word_index_external.p', 'rb') as fp:\n",
    "    word_index = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    global embedding_matrix, embedding_dim\n",
    "    embed_size = embedding_dim\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    # x = CuDNNGRU(100,return_sequences=True)(x)\n",
    "    x = Bidirectional(CuDNNGRU(50, return_sequences=True))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    # x = Conv1D(filters=30, kernel_size=10, strides=2)(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    # x = MaxPooling1D(pool_size = 2)(x)\n",
    "    # x = Flatten()(x)\n",
    "    x = Dense(50)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.layers[1].set_weights([embedding_matrix])\n",
    "    model.layers[1].trainable = False\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train = train.sample(frac=1)\n",
    "\n",
    "list_sentences_train = train[\"comment_text\"].fillna(\"CVxTz\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"CVxTz\").values\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "list_sentences_insult = pd.read_csv('insult.tsv',sep='\\t').comment.fillna('Steeve').values\n",
    "list_sentences_toxicity = pd.read_csv('toxicity.tsv',sep='\\t').comment.fillna('Steeve').values\n",
    "list_sentences_threat = pd.read_csv('threat.tsv',sep='\\t').comment.fillna('Steeve').values\n",
    "\n",
    "# list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "# list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "# X_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "# X_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_tokenized_insult = tokenizer.texts_to_sequences(list_sentences_insult)\n",
    "list_tokenized_toxicity = tokenizer.texts_to_sequences(list_sentences_toxicity)\n",
    "list_tokenized_threat = tokenizer.texts_to_sequences(list_sentences_threat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_i = sequence.pad_sequences(list_tokenized_insult, maxlen=maxlen)\n",
    "X_to = sequence.pad_sequences(list_tokenized_toxicity, maxlen=maxlen)\n",
    "X_th = sequence.pad_sequences(list_tokenized_threat, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.load_weights('weights_base.pre_trained.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4521485e-03, 1.5647619e-04, 1.0364254e-03, 1.8919716e-05,\n",
       "        1.7634697e-03, 1.2914139e-04],\n",
       "       [2.2444291e-04, 1.8916198e-05, 5.1088315e-05, 2.7056192e-06,\n",
       "        1.3747807e-04, 1.7198017e-05],\n",
       "       [4.3097930e-03, 1.6854826e-04, 1.0785871e-03, 2.9034918e-05,\n",
       "        2.2468795e-03, 1.0373683e-04],\n",
       "       ...,\n",
       "       [4.6653749e-05, 1.4479777e-05, 2.2151511e-05, 3.2253174e-06,\n",
       "        3.9215414e-05, 1.4408163e-06],\n",
       "       [4.5463443e-02, 2.7929505e-04, 9.1972034e-03, 1.5820175e-05,\n",
       "        1.6677078e-02, 2.3319499e-04],\n",
       "       [9.4531009e-05, 6.2098865e-05, 6.0262311e-05, 1.2132859e-05,\n",
       "        9.2419366e-05, 3.4128993e-06]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232.0</td>\n",
       "      <td>This:NEWLINE_TOKEN:One can make an analogy in ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216.0</td>\n",
       "      <td>`NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>user</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953.0</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>2002</td>\n",
       "      <td>False</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547.0</td>\n",
       "      <td>`This is such a fun entry.   DevotchkaNEWLINE_...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959.0</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rev_id                                            comment  year  \\\n",
       "0   2232.0  This:NEWLINE_TOKEN:One can make an analogy in ...  2002   \n",
       "1   4216.0  `NEWLINE_TOKENNEWLINE_TOKEN:Clarification for ...  2002   \n",
       "2   8953.0                          Elected or Electoral? JHK  2002   \n",
       "3  26547.0  `This is such a fun entry.   DevotchkaNEWLINE_...  2002   \n",
       "4  28959.0  Please relate the ozone hole to increases in c...  2002   \n",
       "\n",
       "   logged_in       ns  sample  split  \n",
       "0       True  article  random  train  \n",
       "1       True     user  random  train  \n",
       "2      False  article  random   test  \n",
       "3       True  article  random  train  \n",
       "4       True  article  random   test  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('toxicity.tsv',sep='\\t').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
